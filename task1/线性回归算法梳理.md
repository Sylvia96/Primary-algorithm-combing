## 一、机器学习基本概念
### 1、机器学习类别
**有监督学习（Supervised Learning）**：分为Regressione（*输出数值*）和Classification（*输出分类*）  
需要告知input和output，打上label  
**半监督学习（Semi-supervised Learning）**：少量label  
**迁移学习（Transfer Learning）**:  有部分data与task无关  
**无监督学习（Unsupervised Learning）**：只有input没有output      clustering-eg:google news  
  
### 2、泛化能力  
泛化能力（generalization ability）是指一个机器学习算法对于没有见过的样本的识别能力。(举一反三)  
比如，教机器计算2+5，之后算法通过自己的学习可以学会任意一个没有经过人工教过的加法，并在不断的测试中都能算对。  
  
### 3、过拟合与欠拟合  
**过拟合**：模型复杂度高于实际问题，把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质性质，这样就会导致泛化性能下降。导致模型死记硬背的记住指令，而没有理解背后的规律。  
> 高方差  
（1）尽量减少特征的数量  
（2）early stopping  
（3）数据集扩增  
（4）dropout  
（5）正则化包括L1、L2  
（6）清洗数据  

**欠拟合**：与过拟合相对，模型的复杂度较低，没法很好的学习到数据背后的规律。（提取特征较少）  
> 高偏差  
（1）添加其他特征项  
（2）添加多项式特征  
（3）减少正则化参数  
  
参考：https://blog.csdn.net/u012197749/article/details/79766317  
  
### 4.交叉验证
交叉验证是在机器学习建立模型和验证模型参数时常用的办法。交叉验证，顾名思义，就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。  
交叉验证分为下面三种：  
**简单交叉验证**  
**S折交叉验证（S-Folder Cross Validation）**  
**留一交叉验证（Leave-one-out Cross Validation）**  

## 二、线性回归  
**Regression**（输出数值）    
**损失函数**（lost function）：L(w，b) *计算误差*  
**代价函数**: 误差的平均值  
**目标函数**：代价函数 + 正则化项  
  
## 三、优化方法
### 1、梯度下降法  
梯度下降法是一个最优化算法，通常也称为最速下降法。最速下降法是求解无约束优化问题最简单和最古老的方法之一，虽然现在已经不具有实用性，但是许多有效算法都是以它为基础进行改进和修正而得到的。最速下降法是用负梯度方向为搜索方向的，最速下降法越接近目标值，步长越小，前进越慢。  
参考：https://www.cnblogs.com/yhll/p/9238383.html
### 2、牛顿法  
牛顿法法主要是为了解决非线性优化问题，其收敛速度比梯度下降速度更快。其需要解决的问题可以描述为：对于目标函数f(x)，在无约束条件的情况下求它的最小值。    
参考：https://blog.csdn.net/qq_18888869/article/details/82971029  
### 3、拟牛顿法
针对牛顿法中海塞矩阵的计算问题，拟牛顿法主要是使用一个海塞矩阵的近似矩阵来代替原来的还塞矩阵，通过这种方式来减少运算的复杂度。  
参考：https://www.cnblogs.com/liuwu265/p/4714396.html  
  
## 四、线性回归的评估指标  
**平均平方误差**MSE（Mean Squared Error）  
**平均平方误差的平方根**RMSE（Root Mean Squared Error）  
**平均绝对值误差**MAE（Mean Absolute Error）  
**R Squared**  
参考：https://www.jianshu.com/p/9ee85fdad150
  
## 五、sklearn参数详解  
> LinearRegression(fit_intercept=True,normalize=False,copy_X=True,n_jobs=1)  

**fit_intercept**:是否有截据，如果没有则直线过原点。  
**normalize**:是否将数据归一化。 
**copy_X**:默认为True，当为True时，X会被copied,否则X将会被覆写。  
**n_jobs**:默认值为1。计算时使用的核数。
